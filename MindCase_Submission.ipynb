{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLvsniwUr_Im"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install langchain\n",
        "!pip install chromadb\n",
        "!nvidia-smi\n",
        "!pip install angle-emb\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iPk_Zn2rObdq"
      },
      "outputs": [],
      "source": [
        "import torch                                       #deep learning\n",
        "from langchain import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
        "import os\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "import chromadb\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from angle_emb import AnglE, Prompts\n",
        "angle = AnglE.from_pretrained('WhereIsAI/UAE-Large-V1', pooling_strategy='cls').cuda()\n",
        "angle.set_prompt(prompt=Prompts.C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qebTpLknUrAv",
        "outputId": "64c9fdfa-81a4-42f3-a1e4-332850345e95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xcma3k2R_XKZ"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# PROMPT_TEMPLATE = \"\"\"\n",
        "# Answer the question based only on the following context:\n",
        "# {context}\n",
        "# Answer the question based on the above context: {question}.\n",
        "# Provide a detailed answer.\n",
        "# Don’t justify your answers.\n",
        "# Don’t give information not mentioned in the CONTEXT INFORMATION.\n",
        "# Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n",
        "# \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O0_sV842zPjx"
      },
      "outputs": [],
      "source": [
        "DOC_PATH = \"/content/script.pdf\"\n",
        "CHROMA_PATH = \"your_db_name\"\n",
        "\n",
        "# ----- Data Indexing Process -----\n",
        "\n",
        "# load your pdf doc\n",
        "loader = PyPDFLoader(DOC_PATH)\n",
        "pages = loader.load()\n",
        "\n",
        "# split the doc into smaller chunks i.e. chunk_size=500\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "chunks = text_splitter.split_documents(pages)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whole_script=[chunks[i].page_content for i in range(len(chunks))]"
      ],
      "metadata": {
        "id": "ohHilir2A0HY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = chromadb.PersistentClient(path=\"/content/here\")\n",
        "client = client.get_or_create_collection(name=\"test\")"
      ],
      "metadata": {
        "id": "IgAnGHRtXJgK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp=[{'text': text} for text in whole_script]\n",
        "vecs = angle.encode(inp, to_numpy=True)\n",
        "# print(len(vecs))\n",
        "ids=[\"text_\"+str(j+1) for j in range(len(whole_script))]\n",
        "print(ids)\n",
        "client.add(\n",
        "    embeddings = vecs,\n",
        "    documents = whole_script,\n",
        "    ids = ids)"
      ],
      "metadata": {
        "id": "ne-8NXs1WQWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autoawq"
      ],
      "metadata": {
        "id": "iNOfZuJqcc8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optimum"
      ],
      "metadata": {
        "id": "YqOY1uduc380"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install auto-gptq"
      ],
      "metadata": {
        "id": "y9gMSG0Sc_P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-rQhjr5xzPj-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, MusicgenForConditionalGeneration\n",
        "\n",
        "model_name_or_path = \"TheBloke/zephyr-7B-beta-GPTQ\"\n",
        "# To use a different branch, change revision\n",
        "# For example: revision=\"gptq-4bit-32g-actorder_True\"\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name_or_path,device_map=\"auto\")\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id= \"TheBloke/zephyr-7B-beta-GPTQ\""
      ],
      "metadata": {
        "id": "OtDO6hwTiWBJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrive_topK(query=[],topk=5):\n",
        "    client = chromadb.PersistentClient(path=\"/content/here\")\n",
        "    here = client.get_or_create_collection(name=\"test\")\n",
        "    inp=[{'text': text} for text in query]\n",
        "    query_embeddings = angle.encode(inp, to_numpy=True)\n",
        "    results = here.query(\n",
        "        query_embeddings=query_embeddings,\n",
        "        n_results=topk\n",
        "    )\n",
        "    return results['documents']"
      ],
      "metadata": {
        "id": "YWnuB1H1YFhS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt template\n",
        "PROMPT_TEMPLATE =\"\"\"\n",
        "<|system|>\n",
        "You are a great AI which can retrive answer from a given context very concisely. If the answer is not explicitly present in the context, you need to provide a summarization of the points referencing the answer mentioned in the context.\n",
        "</s>\n",
        "\n",
        "<|user|>\n",
        "Answer the question based only on the following context:\n",
        "{context}\n",
        "Answer the question based on the above context: {question}.\n",
        "\n",
        "</s>\n",
        "\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate(input_variables=[\"context\", \"question\"], template=PROMPT_TEMPLATE)"
      ],
      "metadata": {
        "id": "z5DAGdffZr8t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer_from_context_and_query(prompt_template, model_id, context_text, query):\n",
        "    # tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "    # model = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit=False, max_length=600)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
        "                                             device_map=\"auto\",\n",
        "                                             trust_remote_code=False,\n",
        "                                             revision=\"main\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
        "    input_text = prompt_template.format(context=context_text, question=query)\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=512)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "1fcfla8_Zazj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template"
      ],
      "metadata": {
        "id": "B66vGUI_lE0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = retrive_topK([\"Explain the theme of the movie?\"])\n",
        "query = \"Explain the theme of the movie?\"\n",
        "# print(context_text)"
      ],
      "metadata": {
        "id": "w1bs_Rt8YJEw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hdJCe_sDzPj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66048328-53ea-4017-b503-308a617010a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1363: UserWarning: Current model requires 1042646016 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1477: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<|system|>\n",
            "You are a great AI which can retrive answer from a given context very concisely. If the answer is not explicitly present in the context, you need to provide a summarization of the points referencing the answer mentioned in the context.\n",
            " \n",
            "\n",
            "<|user|>\n",
            "Answer the question based only on the following context:\n",
            "[['RICK DECKARD / SUBJECT # N6RRP40619.Up comes A EXTREME-CLOSE IMAGE OF...AN EYELARGE.  LOVELY.  A rich green we so far haven’t seen in the film.  AN OLD VOIGHT-KAMPFF RECORDING.  The eye BLINKS.Over it comes a JUMBLE OF VOICES, falling in and out, incomplete audio.  YET ALL HAUNTINGLY FAMILIAR.ON K.  WATCHING, AS --MAN’S VOICE (O.S.)Have a little boy--butterfly collection plus the killing----Feel a wasp crawling on your wrist----Just answer the question--WOMAN’S VOICE (O.S.)--I’d take him to the', 'of dust.  Death creeping in.  Nearly there.A thin SOUND in the distance.  FOOTSTEPS.  Feet pass Deckard’s blaster covered in ash.  A beat.THEN K IS DRAGGED BACKWARDS ACROSS THE FLOOR.FADE TO BLACK.CLOSE ON:  A HORSE’S FACE.  LIPS PARTED, NOSTRILS FLARED IN PERMANENT ANGUISH.CUT TO:EXT. DESERT. NIGHT.CLOSE ON:  FIRELIGHT.  SMOKE.  A CRACKLE AND SPARK.K’S EYES FLUTTER OPEN.  FEVERED AND AFRAID.  HE SEES A CAMPFIRE BURNING...SENSES A HUMAN PRESENCE BESIDE HIM.  HIS EYES CLOSE AGAIN...FADE TO', 'fragile mood.  Suddenly no longer in the mood for pain.DECKARD (cont’d)We can keep at it.  Or we can get a drink.A beat.  K has no idea what to make of Deckard.  He picks up the dropped blaster.KI’d take a drink.DECKARDGood answer.And he steps out.  Off K...  following after...  the dog behind them...  and Elvis still singing, we --CUT TO:INT. K’S APARTMENT COMPLEX STAIRS. NIGHT.Luv goes up the stairs, searching.INT. K’S APARTMENT. NIGHT.CLOSE ON:  THE DOOR.  TEARING OPEN.  BRUTE', 'Seeking.  Then...It locks in on something.  Begins a straight line for...THE CASINOINT. LUV’S SPINNER. DAWN.As Luv closes in, A PROMPT comes UPSCREEN.ON IT:  THE PILOTFISH’S VIEW of Deckard’s penthouse.  Two bodies within.  “TARGET LOCKED.  DETONATE?”LUVNo.  Hold.UPSCREEN:  “CERTAIN?”LUV (cont’d)Certain.UPSCREEN:  “CERTAIN?”LUV (cont’d)Quite.She banks the Spinner around the hotel, as --EXT. TERRACE. PENTHOUSE FLOOR SUITE. DAWN.K looks at sunrise, lying on a patio chair, freezing.  A wide', 'nothing.  Hating to disappoint him.  A pause.  Then the Barracuda moves past Luv.  It joins...A SMALL CLUSTER of BARRACUDAS that float toward Luv in the LIT center of the room.  They undulate in watery formation at eye level like Medusa would ask of her snakes, to precede --NIANDER WALLACEShadow shrouded.  Commanding in his silences, which are few.  Older, yet at the height of powers that still increase as if by magic.  Only when he steps into the LIGHT do we see --WALLACE IS BLIND.  The probes']]\n",
            "Answer the question based on the above context: Explain the theme of the movie?.\n",
            "\n",
            " \n",
            "\n",
            "<|assistant|>\n",
            "Based on the given context, it is challenging to determine a specific theme for the movie as the provided snippets appear to be disconnected scenes without a clear narrative or overarching message. However, some possible themes that could be inferred from the context include:\n",
            "\n",
            "1. Identity and memory: The recurring images of eyes and memories, as well as the use of the Voight-Kampff test to distinguish replicants from humans, suggest a focus on identity and memory.\n",
            "2. Mortality and the human condition: The scenes of death and decay, as well as the references to pain and fragility, suggest a contemplation of mortality and the human condition.\n",
            "3. Technology and its impact on society: The presence of advanced technology, such as replicants and the Spinner, suggests a commentary on the role of technology in society and its potential consequences.\n",
            "4. Deception and perception: The use of deception and misdirection, such as the false leads and hidden agendas, suggests a focus on deception and perception.\n",
            "5. Justice and morality: The conflict between Deckard and the replicants raises questions about justice and morality, particularly in a society where replicants are created to serve humans.\n",
            "\n",
            "However, without a complete viewing of the movie, it is difficult to determine the exact theme or themes that the film explores.\n"
          ]
        }
      ],
      "source": [
        "# Generate and print answer based on context and query\n",
        "answer = generate_answer_from_context_and_query(prompt_template, model_id, context_text, query)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explain the theme of the movie?**\n",
        "1. Identity and memory: The recurring images of eyes and memories, as well as the use of the Voight-Kampff test to distinguish replicants from humans, suggest a focus on identity and memory.\n",
        "2. Mortality and the human condition: The scenes of death and decay, as well as the references to pain and fragility, suggest a contemplation of mortality and the human condition.\n",
        "3. Technology and its impact on society: The presence of advanced technology, such as replicants and the Spinner, suggests a commentary on the role of technology in society and its potential consequences.\n",
        "4. Deception and perception: The use of deception and misdirection, such as the false leads and hidden agendas, suggests a focus on deception and perception.\n",
        "5. Justice and morality: The conflict between Deckard and the replicants raises questions about justice and morality, particularly in a society where replicants are created to serve humans.\n",
        "\n",
        "However, without a complete viewing of the movie, it is difficult to determine the exact theme or themes that the film explores."
      ],
      "metadata": {
        "id": "RC6VQTKFwDe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = retrive_topK([\"Who are the characters? \"])\n",
        "query = \"Who are the characters?\"\n",
        "\n",
        "answer = generate_answer_from_context_and_query(prompt_template, model_id, context_text, query)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "B3nshIW2Yz6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82541307-31d0-46e2-d3e4-bc90e7fe8504"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1363: UserWarning: Current model requires 1042646016 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1477: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<|system|>\n",
            "You are a great AI which can retrive answer from a given context very concisely. If the answer is not explicitly present in the context, you need to provide a summarization of the points referencing the answer mentioned in the context.\n",
            " \n",
            "\n",
            "<|user|>\n",
            "Answer the question based only on the following context:\n",
            "[['K (V.O.)I go looking for a hiding place.  There’s nowhere to go but this... dark furnace.  It’s very dark.  I’m very scared...  But this horse is all I have so I go in anyway.A FURNACE RAGES WITH FIRE.  He moves to THE DARK PLACES BEHIND.  The child’s hand opens a secret space in the back.THE LARGER BOYS FIND THE CHILD IN FRONT OF THE FLAMES.K (V.O.)They find me and beat me to tell them where is it.  But I don’t.INT. K’S APARTMENT. RESUME SCENE.BACK TO:  K.  His eyes open.  The spell of memory', 'in darkness.Seeing K, the CHILDREN stop still.  Eyes wide and astonished.  If they’ve ever seen anyone like him it wasn’t lately.They circle K like he was a newfound species.  Fascinated.  All wanting to poke at him... touch his clothes.AN ORPHAN BOY TAKES K’S HAND.  Begins to lead him through.They pass A GIRL curled up with a handcrafted DOLL, its “skin” made of scales fashioned from flattened soda cans.A SHRILL WHISTLE BLASTS from far off.  The children all return to their seats on the', 'Walking up 80 stories.  Stiff from the fight.  An OLD WOMAN bumps into him, expecting him to get out of her way.  No one he passes the least glad to see a Replicant.INT. HALLWAY.K crosses the hall.  ALL his NEIGHBORS’ DOORS are open like market stalls letting in air and letting out CHILDREN.  Every home thickly filled, like a hoarder’s garage.  Some host SHOPS.  FOOD STALLS.  Every floor like a town square.K walks past and to his apartment.  A BOY, brown-faced, missing an ear, looking up at K,', 'nothing.  Hating to disappoint him.  A pause.  Then the Barracuda moves past Luv.  It joins...A SMALL CLUSTER of BARRACUDAS that float toward Luv in the LIT center of the room.  They undulate in watery formation at eye level like Medusa would ask of her snakes, to precede --NIANDER WALLACEShadow shrouded.  Commanding in his silences, which are few.  Older, yet at the height of powers that still increase as if by magic.  Only when he steps into the LIGHT do we see --WALLACE IS BLIND.  The probes', '(MORE)']]\n",
            "Answer the question based on the above context: Who are the characters?.\n",
            "\n",
            " \n",
            "\n",
            "<|assistant|>\n",
            "Based on the given context, the characters mentioned are:\n",
            "\n",
            "1. K (V.O.)\n",
            "2. Child\n",
            "3. Larger boys\n",
            "4. Children (plural)\n",
            "5. Old woman\n",
            "6. Neighbors (plural)\n",
            "7. Boy (brown-faced, missing an ear)\n",
            "8. Luv (presumably a person)\n",
            "9. Barracudas (plural)\n",
            "10. Niander Wallace (presumably a person)\n",
            "\n",
            "Note: The context provided does not give a clear indication of the relationships between these characters, so it is unclear if they are all separate individuals or if some are related in some way.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Who are the characters?**\n",
        "\n",
        "Based on the given context, the characters mentioned are:\n",
        "\n",
        "1. K (V.O.)\n",
        "2. Child\n",
        "3. Larger boys\n",
        "4. Children (plural)\n",
        "5. Old woman\n",
        "6. Neighbors (plural)\n",
        "7. Boy (brown-faced, missing an ear)\n",
        "8. Luv (presumably a person)\n",
        "9. Barracudas (plural)\n",
        "10. Niander Wallace (presumably a person)\n",
        "\n",
        "Note: The context provided does not give a clear indication of the relationships between these characters, so it is unclear if they are all separate individuals or if some are related in some way."
      ],
      "metadata": {
        "id": "Fe0UgHkh05cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = retrive_topK([\"How many male and female characters are in the movie?\"])\n",
        "query = \"How many male and female characters are in the movie?\"\n",
        "\n",
        "answer = generate_answer_from_context_and_query(prompt_template, model_id, context_text, query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUZoA40TtV0G",
        "outputId": "9212eb20-3a1b-43ce-8813-13daa9e89c2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1363: UserWarning: Current model requires 1042646016 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1477: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<|system|>\n",
            "You are a great AI which can retrive answer from a given context very concisely. If the answer is not explicitly present in the context, you need to provide a summarization of the points referencing the answer mentioned in the context.\n",
            " \n",
            "\n",
            "<|user|>\n",
            "Answer the question based only on the following context:\n",
            "[['RICK DECKARD / SUBJECT # N6RRP40619.Up comes A EXTREME-CLOSE IMAGE OF...AN EYELARGE.  LOVELY.  A rich green we so far haven’t seen in the film.  AN OLD VOIGHT-KAMPFF RECORDING.  The eye BLINKS.Over it comes a JUMBLE OF VOICES, falling in and out, incomplete audio.  YET ALL HAUNTINGLY FAMILIAR.ON K.  WATCHING, AS --MAN’S VOICE (O.S.)Have a little boy--butterfly collection plus the killing----Feel a wasp crawling on your wrist----Just answer the question--WOMAN’S VOICE (O.S.)--I’d take him to the', 'and the second back off, put off.  Punk Doxie (MARIETTE) doesn’t seem to mind.  She gives her most inviting grin.  But K’s not interested.MARIETTE (cont’d)Buy a lady a cigarette?(off his silence)You don’t even smile.KIt only encourages.  I’m working.MARIETTEYou’re drinking.KOne helps the other.  You heard your friends.  You know what I am.MARIETTEYes.  A guy eating noodles. 30.', 'You’re free.  Free to meet your daughter.Tough as he is -- Deckard is overcome with emotion for the first time in decades.  Just hearing the word.  Brings himself to say it.DECKARDDaughter...?Everything he longed for.  In a word.  In time he breathes.CUT TO:EXT. SKIES ABOVE LOS ANGELES. DAWN.The grand CITYSCAPE.  Under a blanket of snow.  Clean as a fresh start.EXT. SNOWY FIELD. DAWN.K and Deckard trudge through the snowfall.  The Spinner behind them.  K limps to their destination.  Looks up', 'She comes with the HALO -- which attaches with a practiced motion neatly into a FLASH SHOE on the back of Wallace’s head at the lambdoidal suture.  The electrodes fit into wetware receivers within and... the device glows to match the new light in the Barracudas’ eyes, enabled.Luv’s hands shake as she closes the box.  Beyond respect, she lives in perpetual awe of him.A formation of BARRACUDAS come around Wallace...  Then moves toward the Replicant model predatorily.CUT TO:INT. CRECHE. MOMENTS', 'Walking up 80 stories.  Stiff from the fight.  An OLD WOMAN bumps into him, expecting him to get out of her way.  No one he passes the least glad to see a Replicant.INT. HALLWAY.K crosses the hall.  ALL his NEIGHBORS’ DOORS are open like market stalls letting in air and letting out CHILDREN.  Every home thickly filled, like a hoarder’s garage.  Some host SHOPS.  FOOD STALLS.  Every floor like a town square.K walks past and to his apartment.  A BOY, brown-faced, missing an ear, looking up at K,']]\n",
            "Answer the question based on the above context: How many male and female characters are in the movie?.\n",
            "\n",
            " \n",
            "\n",
            "<|assistant|>\n",
            "Based on the given context, it is unclear how many male and female characters are in the movie. The context only provides brief snippets of dialogue and actions, and does not provide a comprehensive list of all the characters in the movie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How many male and female characters are in the movie?**\n",
        "\n",
        "Based on the given context, it is unclear how many male and female characters are in the movie. The context only provides brief snippets of dialogue and actions, and does not provide a comprehensive list of all the characters in the movie."
      ],
      "metadata": {
        "id": "x950apVL1SuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = retrive_topK([\"Does the script pass the Bechdel test?\"])\n",
        "query = \"Does the script pass the Bechdel test?\"\n",
        "\n",
        "answer = generate_answer_from_context_and_query(prompt_template, model_id, context_text, query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5REbRXhCxEb7",
        "outputId": "223f1e5f-d763-4ca0-ac1f-ef9d24bc7ede"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1363: UserWarning: Current model requires 1042646016 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1477: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<|system|>\n",
            "You are a great AI which can retrive answer from a given context very concisely. If the answer is not explicitly present in the context, you need to provide a summarization of the points referencing the answer mentioned in the context.\n",
            " \n",
            "\n",
            "<|user|>\n",
            "Answer the question based only on the following context:\n",
            "[['(cont’d)Run it.ANOTHER CHIME.  “ALL EXEGETIC DATA CORRUPTED.”  Annoyed --K (cont’d)Ok.  Then run it raw.  On a rondo.The SLATE recedes.  A FAN begins to WHIR as a VIEWING DEVICE comes to life.  Like an old moviola.  Blinders on each side.  K situates himself in front of it -- CLICKS on the emanator -- and cranks the machine.A DATAFLOW begins on its SCREEN.  A CASCADE OF ONLY FOUR LETTERS:  A-C-T-G.  RAW GENETIC CODE.  WITH NO IDENTIFYING  CONTEXTUAL DATA TO LINK WITH SPECIFIC TRAITS.  ONLY RAW', 'He quiets.  Just then -- K sees something in the dataflow.  Sits up suddenly.K (cont’d)There.  Hold.The snowstorm of LETTERS FREEZES.  K moves close.  Sees something remarkable in the chaos.K (cont’d)Put up 4847 and 2181.  Side by side.The datasets comply.  All other information falls away as two chains of DNA move side by side.  Then OVERLAP so we can see:  THE LETTERS OF EACH OF THEM MATCH EXACTLY.K (cont’d)They’re identical...  Translate.It READS and translates the THE DNA CHAINS.  Sorting', 'FILLED WITH THOUSANDS OF GLASSY SPHERES.  Like eyes milky with cataracts.  She pulls on gloves before handling them.LUVAll our memory bearings from the time.  All fairly well damaged in the Blackout.She locates and inspects one of them.  Particularly cloudy.LUV (cont’d)But there are sometimes fragments.She sets it into a PLAYER device.  The bearing SPINS in the player...  FIRES UP.A title on the record: VOIGHT-KAMPFF TEST NOVEMBER 2019 OFFICER RICK DECKARD / SUBJECT # N6RRP40619.Up comes A', 'an OPTICAL CONTROL ASSAY which fit like glasses.  This as her NAILS are being painted in fabulous detail by an AESTHETICIAN with a micropipette.  Her voice calm and even.LUV200 feet to the east.  Fire.  Go north.  Fire.  Stop.  20 degrees east.  Stop.  Zoom.  Closer.LUV’S POV:  The assay ZOOMS IN ON K.LUV (cont’d)Come on.  Get up.  Do your fucking job.SHE FIRES AGAIN.EXT. TRASH MESA.ANOTHER SHOT BLASTS by the Spinner to rain trash down on K. 50.', 'Tomb. A GREETER meets K and escorts him to --INT. ENTRY. RECORDS LIBRARY. DAY.A dead end corridor.  GREETER goes away in the dark.Leaving K standing before a too-chatty FILE CLERK.  File Clerk’s booth looks like a bunker.KChecking on an old serial number.FILE CLERKYou have anything else?  You have confirmation DNA?KI have hair.K sets the braid on a case.  Clerk SCANS IT.  A SERIAL NUMBER APPEARS ON THE MONITOR.ON HIS MONITOR:  AUTOCAPTURING THE SERIAL NUMBER.  This as --FILE CLERKAn old one.']]\n",
            "Answer the question based on the above context: Does the script pass the Bechdel test?.\n",
            "\n",
            " \n",
            "\n",
            "<|assistant|>\n",
            "No, the script does not pass the Bechdel test as there are no conversations between two named female characters about a topic other than a man. The only female character, LUV, interacts with a male character, K, and their conversation is about K's job and a DNA test. There is also a female voice giving instructions, but it is not clear if she is a named character. Therefore, the script fails the Bechdel test.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Does the script pass the Bechdel test?**\n",
        "\n",
        "No, the script does not pass the Bechdel test as there are no conversations between two named female characters about a topic other than a man. The only female character, LUV, interacts with a male character, K, and their conversation is about K's job and a DNA test. There is also a female voice giving instructions, but it is not clear if she is a named character. Therefore, the script fails the Bechdel test."
      ],
      "metadata": {
        "id": "80LRhjfC1eFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_text = retrive_topK([\"What is the role of Deckard in the movie?\"])\n",
        "query = \"What is the role of Deckard in the movie?\"\n",
        "\n",
        "answer = generate_answer_from_context_and_query(prompt_template, model_id, context_text, query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1ojw2bgxNDC",
        "outputId": "08cad638-7d41-4a59-d0cb-7604af492e06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py:1363: UserWarning: Current model requires 1042646016 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
            "  warnings.warn(\n",
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1477: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<|system|>\n",
            "You are a great AI which can retrive answer from a given context very concisely. If the answer is not explicitly present in the context, you need to provide a summarization of the points referencing the answer mentioned in the context.\n",
            " \n",
            "\n",
            "<|user|>\n",
            "Answer the question based only on the following context:\n",
            "[['it.  So lost in the discovery, he is completely surprised by -- THE CLICK OF A GUN --MAN’S VOICE (O.S.)“You mightn’t happen to have a piece of cheese about you now, boy?”DECKARD’S ICONIC BLASTERComes out of the SHADOWS half into the LIGHT.  PrecedingRICK DECKARDStrong, tireless.  Seasoned by time and, like teak or copper, far more handsome for the patina.  But also something... cracky about him.  Thoughts obscure, running together.  Enough to keep us guessing if he’s gone touched left alone out', 'as --ONE OF THE DARK SPINNERS LANDS INSIDE THE PENTHOUSE.DARK FIGURES get out and DRAG UNCONSCIOUS DECKARD toward the Spinner.  K tries to move for Deckard -- but his abdomen has been PUNCTURED by debris.Deckard fights his captors brutally, but they are too many.Fighting pain, K staggers to his feet.Is GRABBED from behind.K BREAKS the hand that clasped him and DROPS its owner.  Disarms with MAN lugging Deckard and SHOOTS HIM AND ONE MORE.The team doesn’t last long against K unleashed.  Until', 'to him.  Breaks his retrains.K and Deckard dive out of the sinking tomb.IN THE OCEAN.K and Deckard swim.  Wave and current conspire to drown them.A WAVE BATTERS K.  WE LOSE SIGHT OF HIM IN THE WATER.DECKARDJo!Deckard reaches back.  CLASPS K’S HAND.  Helping him back.THE SURFACE EXPLODES.  K GASPS for breath.  ANOTHER WAVE CRASHES them onto the base of THE SEA WALL. 105.', 'You’re free.  Free to meet your daughter.Tough as he is -- Deckard is overcome with emotion for the first time in decades.  Just hearing the word.  Brings himself to say it.DECKARDDaughter...?Everything he longed for.  In a word.  In time he breathes.CUT TO:EXT. SKIES ABOVE LOS ANGELES. DAWN.The grand CITYSCAPE.  Under a blanket of snow.  Clean as a fresh start.EXT. SNOWY FIELD. DAWN.K and Deckard trudge through the snowfall.  The Spinner behind them.  K limps to their destination.  Looks up', 'KICK to destroy his ribs sends him backwards, as --INT. TRANSPORT VAN.The Transport LURCHES.  Water floods in.Deckard struggles to free his still cuffed hand --A colossal wave CRASHES over the Transport, tipping it --EXT. SEPULVEDA SEA WALL.K and Luv pause to see the Transport carried out to sea -- and begin to SINK.  Luv wastes no more time.HER KNIFE SINGSK dodges it -- blocks it -- grabs it by the blade -- not seeing --HER SECOND KNIFEThe blade slips out of K’s gut before he felt it go in.K']]\n",
            "Answer the question based on the above context: What is the role of Deckard in the movie?.\n",
            "\n",
            " \n",
            "\n",
            "<|assistant|>\n",
            "The question asks about the role of Deckard in the movie based on the given context. From the context provided, it can be inferred that Deckard is the main protagonist of the movie. He is described as a seasoned and experienced character, who is strong, tireless, and handsome for his patina. He is also referred to as Rick Deckard, and his iconic blaster is mentioned. Throughout the context, Deckard is involved in various actions, such as fighting his captors, helping K back, and reaching out to save K's hand. His role in the movie seems to be that of a renegade blade runner, who is trying to save K and meet his daughter. Therefore, the answer to the question would be that Deckard is the main protagonist of the movie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the role of Deckard in the movie?**\n",
        "\n",
        "The question asks about the role of Deckard in the movie based on the given context. From the context provided, it can be inferred that Deckard is the main protagonist of the movie. He is described as a seasoned and experienced character, who is strong, tireless, and handsome for his patina. He is also referred to as Rick Deckard, and his iconic blaster is mentioned. Throughout the context, Deckard is involved in various actions, such as fighting his captors, helping K back, and reaching out to save K's hand. His role in the movie seems to be that of a renegade blade runner, who is trying to save K and meet his daughter. Therefore, the answer to the question would be that Deckard is the main protagonist of the movie."
      ],
      "metadata": {
        "id": "wCnIaWok1nFT"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}